# 数据结构与算法图解

1. 事实上，数据结构与算法都是能够从常识推导出来的。
2. 数学符号只是一种特定的语言，数学里的一切都是可以用常识去解释的。

## 第 1 章  数据结构为何重要

1. 编程基本上就是在跟数据打交道。计算机程序总是在接收数据、操作数据或返回数据。
2. 事实上，无论是多么复杂的数据，我们都可以将其拆成一堆数字和字符串来看待。
3. 一般数据结构都有以下4种操作：读取、查找、插入、删除。  
    数组：读取-O(1)、线性查找-O(N)、插入-O(N)、删除-O(N)
4. 一个重要理论：操作的速度，并不按时间计算，而是按步数计算。
5. 这种逐个格子去检查的做法，就是最基本的查找方法——线性查找。
6. 集合就是用于确保数据不重复。

## 第 2 章  算法为何重要

无

## 第 3 章  大O记法

1. 为了统一描述，大O不关注算法所用的时间，只关注其所用的步数。  
    大O记法可用来描述一个函数的增长率的上限。  
    O(1) 被称为常数时间。  
    O(N) 被称为线性时间。  
    O(logN) 被称为对数时间。  
    O(N^2) 被称为二次时间。
2. 大O记法：  
    大O记法忽略常数。  
    大O只保留最高阶的N  
    大O记法不包含一般数字，除非是指数。
3. 若无特别说明，大O记法一般都是指最坏情况。  
    这种悲观主义其实是很有用的：知道各种算法会差到什么程度，能使我们做好最坏打算，以选出最适合的算法。

## 第 4 章  运用大O来给代码提速

1. 当遇到低效的算法时，我们都应该花些时间思考下有没有更快的做法。

## 第 5 章  用或不用大O来优化代码

1. 有时候即使两种算法的大O记法完全一样，但实际上其中一个比另一个要快得多。  
    即使两种算法的大O记法一样，但实际速度也可能并不一样。
2. 大O记法非常适合用于不同大O分类下的算法的对比，对于大O同类的算法，我们还需要进一步的解析才能分辨出具体差异。  
    大O记法只表明，对于不同分类，存在一临界点，在这一点之后，一类算法会快于另一类，并永远保持下去。至于这个点在哪里，大O并不关心。  
    当两种算法落在不同的大O类别时，你就很自然地知道应该选择哪种。  
    因为在大数据的情况下，必然存在一临界点使这两种算法的速度永远区分开来。
3. 选择排序的大O记法跟冒泡排序是一样的。但选择排序的步数大概只有冒泡排序的一半，即选择排序比冒泡排序快一倍。  
    尽管不能比较冒泡排序和选择排序，大O还是很重要的，因为它能够区分不同算法的长期增长率。  
    当数据量达到一定程度时，O(N)的算法就会永远快过 O(N^2)，无论这个 O(N)实际上是O(2N)还是O(100N)
4. 不过在对比算法时，还需要考虑一个重要因素。至今我们关注的都是最坏情况下算法会跑得多慢，但其实最坏情况并不总会发生。没错，我们遇到的大都是平均情况。

## 第 6 章  乐观地调优

1. 在最坏的情况里，插入排序的时间复杂度跟冒泡排序、选择排序一样，都是O(N^2)
2. 最好情况和最坏情况很少发生。现实世界里，最常出现的是平均情况。  
    记住，虽然为最坏情况做好准备十分重要，但大部分时间我们面对的是平均情况。
3. 如果你确信数组是大致有序的，那么插入排序比较好。如果是大致逆序，则选择排序更快。  
    对于平均情况（数组里的值随机分布），它们性能相近。如果你无法确定数据是什么样，那就算是平均情况了，两种都可以。
4. 懂得区分最好、平均、最坏情况，是为当前场景选择最优算法以及给现有算法调优以适应环境变化的关键。

## 第 7 章  查找迅速的散列表

1. 在散列表中查找值的平均效率为O(1)，因为只要一步。
2. 散列表处理冲突的一种经典的做法就是分离链接。当冲突发生时，我们不是将值放到格子里，而是放到该格子所关联的数组里。
3. 如果数据都刚好存在同一个格子里，那么查找就相当于在数组上进行。  
    因此散列表的最坏情况就是O(N)  
    为了避免这种情况，散列表的设计应该尽量减少冲突，以便查找都能以O(1)完成。
4. 使用散列表时需要权衡：既要避免冲突，又要节约空间。  
    要想解决这个问题，可参考计算机科学家研究出的黄金法则：每增加7个元素，就增加10个格子。  
    数据量与格子数的比值称为负载因子。把这个术语代入刚才的理论，就是：理想的负载因子是0.7（7个元素 / 10个格子）。
5. 高效的软件离不开散列表，因为其O(1)的读取和插入带来了无与伦比的性能优势。

## 第 8 章  用栈和队列来构造灵巧的代码

1. 往栈里插入数据，叫作压栈。从栈顶移除数据叫作出栈。  
    压栈和出栈可被形容为LIFO（last in, first out）后进先出。解释起来就是最后入栈的元素，会最先出栈。
2. 栈的特性：只能在末尾插入数据，只能移除末尾的数据。
3. 递归基于栈，递归也是其他几个高级算法的基础。

## 第 9 章  递归

1. 函数调用自身，就叫作递归。
2. 几乎所有循环都能够转换成递归。但能用不代表该用。
3. 不再递归的情形称为基准情形。
4. 计算机是用栈来记录每个调用中的函数。这个栈就叫作调用栈。
5. 无限递归的程序会一直将同一方法加到调用栈上，直到计算机的内存空间不足，最终导致栈溢出的错误。
6. 事实上，递归可以自然地用于实现那些需要重复自身的算法。
7. 改用递归并不会改变算法的大O
8. 正如文件系统的例子所示，递归十分适用于那些无法预估计算深度的问题。

## 第 10 章  飞快的递归算法

1. 之前我们看到的很多算法，最佳情况都发生在元素有序的时候。但在快速排序里，最佳情况应该是每次分区后轴都刚好落在子数组的中间。
2. 快速排序最坏的情况就是每次分区都使轴落在数组的开头或结尾。导致这种情况的原因有好几种，包括数组已升序排列，或已降序排列。
3. 快速排序最坏情况下的效率为O(N^2)
4. 由于快速排序在平均情况下表现优异，于是很多编程语言自带的排序函数都采用它来实现。
5. 快速选择算法用于找出无序数组中第 N 大（或第 N 小）的元素。  
    快速选择的优势在于它不需要把整个数组都排序就可以找到正确位置的值。  
    快速选择的平均情况效率为 O(N)

## 第 11 章  基于结点的数据结构

1. 链表的每个结点除了保存数据，它还保存着链表里的下一结点的内存地址。
2. LinkedList的作用就是一个指针，它指向链表的第一个结点。
3. 链表：读取-O(N)、查找-O(N)、插入-O(1)、删除-O(1)  
    链表的插入和删除操作本身只需要 O(1) ，但插入和删除前往往需要先进行查找操作，所以实际的效率往往是 O(N)
4. 双向链表跟链表差不多，只是它每个结点都含有两个链——一个指向下一结点，另一个指向前一结点。  
    此外，它还能直接访问第一个和最后一个结点。  
    因为双向链表能直接访问前端和末端的结点，所以在两端插入的效率都为 O(1) ，在两端删除的效率也为 O(1)  
    由于在末尾插入和在开头删除都能在 O(1) 的时间内完成，因此拿双向链表作为队列的底层数据结构就最好不过了。

## 第 12 章  让一切操作都更快的二叉树

1. 树也是基于结点的数据结构，但树里面的每个结点，可以含有多个链分别指向其他多个结点。
2. 二叉查找树（Binary Search Tree），（又称：二叉搜索树，二叉排序树）它或者是一棵空树，或者是具有下列性质的二叉树：  
    若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；  
    若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；  
    它的左、右子树也分别为二叉排序树。
3. 二叉树的效率：  
    查找 - O(log N)  
    插入 - O(log N)  
    删除 - O(log N)  
    遍历 - O(N)
4. 只有用随意打乱的数据创建出来的树才有可能是比较平衡的。要是插入的都是已排序的数据，那么这棵树就失衡了，它用起来也会比较低效。
5. 假若你要用有序数组里的数据来创建二叉树，最好先把数据洗乱。
6. 访问数据结构中所有元素的过程，叫作遍历数据结构。
7. 递归是实施中序遍历的有力工具。
8. 图是社交网络和地图软件等复杂应用的核心组成部分，强大且灵活。

## 第 13 章  连接万物的图

1. 按照图的术语来说，每个结点都是一个顶点，每条线段都是一条边。当两个顶点通过一条边联系在一起时，我们会说这两个顶点是相邻的。
2. 图有两种经典的遍历方式：广度优先搜索和深度优先搜索。  
    广度优先搜索算法需要用队列来记录后续要处理哪些顶点。  
    因为广度优先搜索有O(V)次出队，还有O(E)次访问，所以我们说它的效率为O(V + E)

## 第 14 章  对付空间限制

1. 空间复杂度是根据额外需要的内存空间（也叫辅助空间）来算的，也就是说原本的数据不纳入计算。
2. 你最好时刻配备性能测试工具来验证你的调优是否有效。
3. 很多看似复杂、深奥的事物，其实都是由你所掌握的简单概念构筑而成的。不要因为某些资料没解释到位，就以为它很困难而被吓退，你一定能找到更详尽的解释资料。
